{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3b9a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\coding\\\\Data Science\\\\projects\\\\Medical Chatbot with LLMs, LangChain, Pinecone, Flask & AWS\\\\Medical-Chatbot-with-LLMs-LangChain-Pinecone-Flask-AWS\\\\research'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed4dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d776af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a293591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text from pdfs in a directory\n",
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7269af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exctracted_documents = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4065f39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exctracted_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2632962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    minimal_docs: List[Document] = []  # ✅ Correct type hint syntax\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(page_content=doc.page_content, metadata={\"source\": src})\n",
    "        )\n",
    "    return minimal_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c281aab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56bfbd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_docs = filter_to_minimal_docs(exctracted_documents)\n",
    "minimal_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8dee14",
   "metadata": {},
   "source": [
    "# split the doc in chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2411f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text__split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73ffa4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5859\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text__split(minimal_docs)\n",
    "print(len(texts_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f404a879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shriy\\AppData\\Local\\Temp\\ipykernel_21524\\1625399240.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "    )\n",
    "    return embeddings\n",
    "embeddings = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55decc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9022ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03447727486491203,\n",
       " 0.03102312609553337,\n",
       " 0.006734980270266533,\n",
       " 0.026108933612704277,\n",
       " -0.03936205804347992,\n",
       " -0.16030246019363403,\n",
       " 0.06692394614219666,\n",
       " -0.006441438104957342,\n",
       " -0.047450482845306396,\n",
       " 0.014758863486349583,\n",
       " 0.07087534666061401,\n",
       " 0.05552757531404495,\n",
       " 0.019193356856703758,\n",
       " -0.02625126577913761,\n",
       " -0.01010954286903143,\n",
       " -0.026940442621707916,\n",
       " 0.022307462990283966,\n",
       " -0.02222665585577488,\n",
       " -0.14969263970851898,\n",
       " -0.017493024468421936,\n",
       " 0.007676282897591591,\n",
       " 0.054352231323719025,\n",
       " 0.0032544038258492947,\n",
       " 0.03172588348388672,\n",
       " -0.08462139964103699,\n",
       " -0.029405992478132248,\n",
       " 0.051595550030469894,\n",
       " 0.048124078661203384,\n",
       " -0.003314835485070944,\n",
       " -0.05827915295958519,\n",
       " 0.04196925833821297,\n",
       " 0.022210702300071716,\n",
       " 0.1281888633966446,\n",
       " -0.022338951006531715,\n",
       " -0.011656239628791809,\n",
       " 0.06292837113142014,\n",
       " -0.03287634998559952,\n",
       " -0.09122604131698608,\n",
       " -0.03117534890770912,\n",
       " 0.052699536085128784,\n",
       " 0.04703483358025551,\n",
       " -0.08420310169458389,\n",
       " -0.030056182295084,\n",
       " -0.020744839683175087,\n",
       " 0.009517822414636612,\n",
       " -0.003721762914210558,\n",
       " 0.00734331738203764,\n",
       " 0.03932439535856247,\n",
       " 0.09327399730682373,\n",
       " -0.0037885578349232674,\n",
       " -0.05274209380149841,\n",
       " -0.05805816873908043,\n",
       " -0.006864397320896387,\n",
       " 0.005283216945827007,\n",
       " 0.0828929990530014,\n",
       " 0.019362706691026688,\n",
       " 0.006284490693360567,\n",
       " -0.010330768302083015,\n",
       " 0.009032364934682846,\n",
       " -0.037683695554733276,\n",
       " -0.045206066220998764,\n",
       " 0.024016287177801132,\n",
       " -0.006944162305444479,\n",
       " 0.013491649180650711,\n",
       " 0.10005491971969604,\n",
       " -0.07168387621641159,\n",
       " -0.021695099771022797,\n",
       " 0.03161845728754997,\n",
       " -0.05163457617163658,\n",
       " -0.0822477638721466,\n",
       " -0.06569331884384155,\n",
       " -0.009895353578031063,\n",
       " 0.005816371645778418,\n",
       " 0.07355457544326782,\n",
       " -0.03405033051967621,\n",
       " 0.02488613687455654,\n",
       " 0.014488051645457745,\n",
       " 0.02645733952522278,\n",
       " 0.00965669471770525,\n",
       " 0.03021721914410591,\n",
       " 0.05280400812625885,\n",
       " -0.07535992562770844,\n",
       " 0.009897175244987011,\n",
       " 0.02983679808676243,\n",
       " 0.01755562797188759,\n",
       " 0.02309201844036579,\n",
       " 0.0019338484853506088,\n",
       " 0.0014002117095515132,\n",
       " -0.047175947576761246,\n",
       " -0.01119430921971798,\n",
       " -0.11420140415430069,\n",
       " -0.019811974838376045,\n",
       " 0.04026620835065842,\n",
       " 0.002193015068769455,\n",
       " -0.07979219406843185,\n",
       " -0.025382323190569878,\n",
       " 0.09448298066854477,\n",
       " -0.028981072828173637,\n",
       " -0.1450025588274002,\n",
       " 0.23097744584083557,\n",
       " 0.027731169015169144,\n",
       " 0.03211147338151932,\n",
       " 0.03106500953435898,\n",
       " 0.04283282533288002,\n",
       " 0.06423778086900711,\n",
       " 0.03216315060853958,\n",
       " -0.004876742139458656,\n",
       " 0.05569940060377121,\n",
       " -0.03753245621919632,\n",
       " -0.021505557000637054,\n",
       " -0.02834269404411316,\n",
       " -0.028846969828009605,\n",
       " 0.038353074342012405,\n",
       " -0.017468687146902084,\n",
       " 0.052485279738903046,\n",
       " -0.07487601786851883,\n",
       " -0.03125973790884018,\n",
       " 0.021841581910848618,\n",
       " -0.039895690977573395,\n",
       " -0.008587119169533253,\n",
       " 0.026956595480442047,\n",
       " -0.04849553480744362,\n",
       " 0.011469870805740356,\n",
       " 0.029618198052048683,\n",
       " -0.02057221718132496,\n",
       " 0.013103905133903027,\n",
       " 0.02883351780474186,\n",
       " -3.194198350138249e-33,\n",
       " 0.06478210538625717,\n",
       " -0.01813018135726452,\n",
       " 0.05178992450237274,\n",
       " 0.12198279052972794,\n",
       " 0.028780171647667885,\n",
       " 0.008721987716853619,\n",
       " -0.07052117586135864,\n",
       " -0.016907278448343277,\n",
       " 0.04073971137404442,\n",
       " 0.042116183787584305,\n",
       " 0.025447247549891472,\n",
       " 0.03574629873037338,\n",
       " -0.049144718796014786,\n",
       " 0.002128997351974249,\n",
       " -0.01554661151021719,\n",
       " 0.05073055252432823,\n",
       " -0.04818534478545189,\n",
       " 0.035880617797374725,\n",
       " -0.004067136440426111,\n",
       " 0.10172470659017563,\n",
       " -0.05597003176808357,\n",
       " -0.010681075975298882,\n",
       " 0.011235758662223816,\n",
       " 0.09068655222654343,\n",
       " 0.00423447648063302,\n",
       " 0.035138633102178574,\n",
       " -0.009702893905341625,\n",
       " -0.09386512637138367,\n",
       " 0.0928555577993393,\n",
       " 0.008004925213754177,\n",
       " -0.00770544121041894,\n",
       " -0.05208677053451538,\n",
       " -0.012587991543114185,\n",
       " 0.003266935469582677,\n",
       " 0.006013551261276007,\n",
       " 0.007581597194075584,\n",
       " 0.01051716785877943,\n",
       " -0.08634556829929352,\n",
       " -0.06987878680229187,\n",
       " -0.002533907536417246,\n",
       " -0.09097649902105331,\n",
       " 0.046887341886758804,\n",
       " 0.052076555788517,\n",
       " 0.007193804252892733,\n",
       " 0.010903613641858101,\n",
       " -0.005229524336755276,\n",
       " 0.013937273994088173,\n",
       " 0.021968383342027664,\n",
       " 0.03420863673090935,\n",
       " 0.06022472307085991,\n",
       " 0.00011663129407679662,\n",
       " 0.0147319370880723,\n",
       " -0.07008928060531616,\n",
       " 0.02849903330206871,\n",
       " -0.02760171703994274,\n",
       " 0.010768436826765537,\n",
       " 0.03483092784881592,\n",
       " -0.022487863898277283,\n",
       " 0.009769013151526451,\n",
       " 0.07722778618335724,\n",
       " 0.02158835344016552,\n",
       " 0.11495622247457504,\n",
       " -0.06800112128257751,\n",
       " 0.023760998621582985,\n",
       " -0.015983954071998596,\n",
       " -0.017826983705163002,\n",
       " 0.06439491361379623,\n",
       " 0.032025717198848724,\n",
       " 0.050270259380340576,\n",
       " -0.005913740489631891,\n",
       " -0.03370802477002144,\n",
       " 0.017840281128883362,\n",
       " 0.01657339744269848,\n",
       " 0.0632966086268425,\n",
       " 0.034677211195230484,\n",
       " 0.04647349566221237,\n",
       " 0.09790609776973724,\n",
       " -0.006635513622313738,\n",
       " 0.025207048282027245,\n",
       " -0.07798825949430466,\n",
       " 0.016926418989896774,\n",
       " -0.0009457779233343899,\n",
       " 0.022471917793154716,\n",
       " -0.03825320303440094,\n",
       " 0.09570479393005371,\n",
       " -0.005350787658244371,\n",
       " 0.010469076223671436,\n",
       " -0.11524051427841187,\n",
       " -0.013262561522424221,\n",
       " -0.010709395632147789,\n",
       " -0.08311726897954941,\n",
       " 0.07327356934547424,\n",
       " 0.04939223825931549,\n",
       " -0.00899433996528387,\n",
       " -0.09584550559520721,\n",
       " 3.366148929092564e-33,\n",
       " 0.12493181973695755,\n",
       " 0.01934974081814289,\n",
       " -0.05822570249438286,\n",
       " -0.03598824888467789,\n",
       " -0.050746724009513855,\n",
       " -0.04566236957907677,\n",
       " -0.08260342478752136,\n",
       " 0.14819477498531342,\n",
       " -0.08842118829488754,\n",
       " 0.06027447059750557,\n",
       " 0.05103014037013054,\n",
       " 0.010303172282874584,\n",
       " 0.14121423661708832,\n",
       " 0.030813811346888542,\n",
       " 0.06103315204381943,\n",
       " -0.052851274609565735,\n",
       " 0.13664892315864563,\n",
       " 0.009189884178340435,\n",
       " -0.01732519268989563,\n",
       " -0.012848627753555775,\n",
       " -0.00799529068171978,\n",
       " -0.05098007991909981,\n",
       " -0.05235067382454872,\n",
       " 0.007593018934130669,\n",
       " -0.015166306868195534,\n",
       " 0.01696031726896763,\n",
       " 0.021270545199513435,\n",
       " 0.020558075979351997,\n",
       " -0.12002813071012497,\n",
       " 0.01446185540407896,\n",
       " 0.026759909465909004,\n",
       " 0.025330649688839912,\n",
       " -0.04275461286306381,\n",
       " 0.006768523249775171,\n",
       " -0.01445859856903553,\n",
       " 0.04526195675134659,\n",
       " -0.09147650748491287,\n",
       " -0.019439177587628365,\n",
       " -0.017833411693572998,\n",
       " -0.054910145699977875,\n",
       " -0.05264107510447502,\n",
       " -0.010459030978381634,\n",
       " -0.05201607942581177,\n",
       " 0.02089197374880314,\n",
       " -0.07997031509876251,\n",
       " -0.012111341580748558,\n",
       " -0.05773143470287323,\n",
       " 0.023178255185484886,\n",
       " -0.008031717501580715,\n",
       " -0.02598929964005947,\n",
       " -0.07995675504207611,\n",
       " -0.02072884514927864,\n",
       " 0.04881766065955162,\n",
       " -0.020389163866639137,\n",
       " -0.04917655140161514,\n",
       " 0.014159641228616238,\n",
       " -0.06362203508615494,\n",
       " -0.007807410322129726,\n",
       " 0.016431529074907303,\n",
       " -0.025682512670755386,\n",
       " 0.013381082564592361,\n",
       " 0.026248749345541,\n",
       " 0.009978425689041615,\n",
       " 0.06322886049747467,\n",
       " 0.0026721833273768425,\n",
       " -0.006582764443010092,\n",
       " 0.016631918027997017,\n",
       " 0.03236647695302963,\n",
       " 0.037942491471767426,\n",
       " -0.03637608885765076,\n",
       " -0.00691094808280468,\n",
       " 0.00015967199578881264,\n",
       " -0.0016335744876414537,\n",
       " -0.027278205379843712,\n",
       " -0.028038082644343376,\n",
       " 0.049681469798088074,\n",
       " -0.028867201879620552,\n",
       " -0.0024180635809898376,\n",
       " 0.014774911105632782,\n",
       " 0.009764522314071655,\n",
       " 0.0057976427488029,\n",
       " 0.013486180454492569,\n",
       " 0.005567898042500019,\n",
       " 0.03722712770104408,\n",
       " 0.007232568226754665,\n",
       " 0.0401562824845314,\n",
       " 0.08150329440832138,\n",
       " 0.0719916895031929,\n",
       " -0.013056193478405476,\n",
       " -0.042882055044174194,\n",
       " -0.011011265218257904,\n",
       " 0.004897848702967167,\n",
       " -0.009229736402630806,\n",
       " 0.03519150987267494,\n",
       " -0.05103505402803421,\n",
       " -1.571437735492509e-08,\n",
       " -0.08862441778182983,\n",
       " 0.02390933223068714,\n",
       " -0.016238776966929436,\n",
       " 0.0317004919052124,\n",
       " 0.02728421799838543,\n",
       " 0.05246885120868683,\n",
       " -0.047070927917957306,\n",
       " -0.05884743481874466,\n",
       " -0.06320816278457642,\n",
       " 0.04088856652379036,\n",
       " 0.049827951937913895,\n",
       " 0.10655169188976288,\n",
       " -0.07450232654809952,\n",
       " -0.01249542087316513,\n",
       " 0.01837068982422352,\n",
       " 0.039474111050367355,\n",
       " -0.024797888472676277,\n",
       " 0.014516275376081467,\n",
       " -0.037069227546453476,\n",
       " 0.020015744492411613,\n",
       " -4.8564306780463085e-05,\n",
       " 0.009866592474281788,\n",
       " 0.024838760495185852,\n",
       " -0.052458155900239944,\n",
       " 0.0293141920119524,\n",
       " -0.08719189465045929,\n",
       " -0.014499715529382229,\n",
       " 0.026019079610705376,\n",
       " -0.018746377900242805,\n",
       " -0.07620511204004288,\n",
       " 0.03504331782460213,\n",
       " 0.10363952070474625,\n",
       " -0.028050491586327553,\n",
       " 0.01271819043904543,\n",
       " -0.07632547616958618,\n",
       " -0.018652357161045074,\n",
       " 0.024976696819067,\n",
       " 0.08144534379243851,\n",
       " 0.06875885277986526,\n",
       " -0.06405666470527649,\n",
       " -0.08389385789632797,\n",
       " 0.0613623782992363,\n",
       " -0.033545542508363724,\n",
       " -0.10615336894989014,\n",
       " -0.04008054360747337,\n",
       " 0.03253024443984032,\n",
       " 0.07662481814622879,\n",
       " -0.07301618903875351,\n",
       " 0.00033757087658159435,\n",
       " -0.040871601551771164,\n",
       " -0.0757884755730629,\n",
       " 0.0275277066975832,\n",
       " 0.0746254101395607,\n",
       " 0.01771729439496994,\n",
       " 0.0912184864282608,\n",
       " 0.11022017151117325,\n",
       " 0.0005698017776012421,\n",
       " 0.051463354378938675,\n",
       " -0.01455135177820921,\n",
       " 0.03323202580213547,\n",
       " 0.02379227988421917,\n",
       " -0.022889869287610054,\n",
       " 0.0389375165104866,\n",
       " 0.030206838622689247]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embeddings.embed_query(\"Hello world\")\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4520bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ad808b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a498b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68bab3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pinecone_api_key=PINECONE_API_KEY\n",
    "pc=Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d94404e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.control.pinecone.Pinecone at 0x2d5840d3970>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46b1adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "# Define index name\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# Check if index exists\n",
    "existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # must match your embedding model output dimension\n",
    "        metric=\"cosine\",  # correct spelling\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "# Get reference to the index\n",
    "index = pc.Index(index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5109acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "docset=PineconeVectorStore.from_documents(documents=texts_chunk, embedding=embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05a6c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_existing_index(embedding=embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed597e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff0e9d11",
   "metadata": {},
   "source": [
    "# Add more data in exixting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5fde5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e7bf1c1d-556f-4d1d-9e71-d1766de6b275']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dswith=Document(page_content=\"New medical information to add to the existing index.\", metadata={\"source\": \"new_medical_doc.pdf\"})\n",
    "docsearch.add_documents([dswith])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cde5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a430a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3b489ec0-07e8-404c-a6d3-053956028f8d', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='(BPH), a condition that affects men and is characterized\\nby an enlarged prostate gland.\\nHigh blood pressure\\nHigh blood pressure puts a strain on the heart and\\nthe arteries. Over time, hypertension can damage the\\nblood vessels to the point of causing stroke, heart fail-\\nure or kidney failure. People with high blood pressure\\nmay also be at higher risk for heart attacks. Controlling\\nhigh blood pressure makes these problems less likely.\\nAlpha blockers help lower blood pressure by causing'),\n",
       " Document(id='2b486c60-747f-4deb-8c9f-8c1164df9986', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='heart and lungs.\\n• Seek treatment for hypertension—High blood pressure\\ncan be controlled through lifestyle changes—reducing\\nsodium and fat, exercising, managing stress, quitting\\nKEY TERMS\\nArteriosclerosis —Hardening of the arteries. It\\nincludes atherosclerosis, but the two terms are\\noften used synonymously.\\nCholesterol—A fat-like substance that is made by\\nthe human body and eaten in animal products.\\nCholesterol is used to form cell membranes and\\nprocess hormones and vitamin D. High choles-'),\n",
       " Document(id='c4a359c7-e35c-4934-84ef-3f24e28eb0ad', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='Hypertension—Persistently high arterial blood pres-\\nsure.\\nNeurotransmitter —Substance released from neu-\\nrons of the peripheral nervous system that travels\\nacross the synaptic clefts (gaps) of other neurons to\\nexcite or inhibit the target cell.\\nPalpitation—Rapid, forceful, throbbing, or fluttering\\nheartbeat.\\nReceptor—A molecular structure in a cell or on the\\nsurface of a cell that allows binding of a specific\\nsubstance that causes a specific physiologic\\nresponse.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrived_docs = retriever.invoke(\"What is hypertension?\")\n",
    "retrived_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9a5d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1️⃣ Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# 2️⃣ Initialize Gemini model using API key\n",
    "chatModel = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\")   # 👈 this line is crucial\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "413ed2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8ab5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = (\"You are a helpful medical assistant for answering questions based on the provided context.\"\n",
    "\"Use ht following pieces of retrieved documents to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
    "\"Use three sentences maximum to answer the question.\"\n",
    "\"answer concisely and accurately.\"\n",
    "\"\\n\\n\"\n",
    "\"{context}\"\n",
    ")\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [   (\"system\",system_template),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a196b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(\n",
    "    chatModel,\n",
    "    prompt          # the ChatPromptTemplate we created earlier\n",
    ")\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92280557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba7827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
